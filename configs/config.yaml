mode: prod # Set to dev when testing, otherwise set to prod

critic:
  type: "causal"
  name:  "google/gemma-3-4b-it" # "google/flan-t5-base"
  device: cuda
  is_openrouter: false

experts:
  num_experts: 2
  type: "seq2seq" # causal
  name: "google/flan-t5-small" # HuggingFaceTB/SmolLM2-135M
  device: cuda
  debate_rounds: 5
  feedback_size: 100
  batch_size: 10
  
model_params:
  max_new_tokens: 256
  temperature: 0.7
  do_sample: true
  top_p: 0.9
  num_return_sequences: 1
  min_new_tokens: 10

lora:
  enabled: true
  r: 8
  lora_alpha: 16
  lora_dropout: 0.1
  bias: "none"

memory_ft:
  max_steps: 200
  learning_rate: 1e-5

training:
  output_dir: "./results"
  eval_strategy: "steps"
  save_strategy: "no"
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 4
  eval_accumulation_steps: 4
  eval_steps: 500
  max_steps: 200
  logging_steps: 20
  learning_rate: 1e-5
  weight_decay: 0.01

data:
  data_cache_dir: "./data/cache"
  category: "summarization" # "summarization" or "math" or "translation"
  name: "samsum" # "gsm8k" or "samsum" or "opus"
  split: ["train[:10%]+validation[:5%]+test[:5%]"]